## Технологическая архитектура 

На первом этапе важно создать гибкую среду для быстрых экспериментов и
проверки гипотез. Платформа для пилотов должна позволять запускать
генеративные модели (LLM), решения класса Retrieval-Augmented Generation
(RAG), базовые ML-модели для прогнозов и компьютерное зрение (CV) без
долгих циклов согласования и закупок.

Инфраструктурно используется гибридная модель: облачные мощности - для
не чувствительных к данным задач (чат-ассистенты, поиск по открытым
нормативным документам), локальные вычислительные ресурсы - для ИИ,
работающего с корпоративными данными (нормативно-техническая
документация, телеметрия, отчёты).

Минимальный технологический стек включает объектное хранилище для данных
(MinIO или аналог S3-класса), векторную базу данных (Qdrant или
pgvector) для RAG-сценариев, систему каталогизации и качества данных
(OpenMetadata, Great Expectations), оркестратор задач (Airflow или
Prefect) и инструменты для версионирования и экспериментов (MLflow). Для
генеративных решений применяются облачные или приватные LLM (Llama 3,
Falcon, KazLLM), а для CV и ML - PyTorch, TensorRT и Triton Inference
Server.

Такая архитектура позволяет быстро запускать ИИ-инициативы, не дублируя
инфраструктуру. Она ориентирована на типы искусственного интеллекта,
которые дают быстрый эффект: генеративный ИИ (LLM, RAG) - для
корпоративных ассистентов и анализа документации; классический ML и CV -
для диагностики инфраструктуры и прогнозов отказов оборудования.

### Платформа для масштабирования и промышленного внедрения

По мере накопления опыта и появления устойчивых бизнес-кейсов платформа
ИИ должна перейти к промышленной архитектуре, обеспечивающей
масштабирование и управляемость. Это уровень, на котором ИТ-ландшафт
превращается в единое пространство данных и моделей.

Ключевым элементом становится корпоративный слой данных, объединяющий
телеметрию, данные перевозок, ремонтов, клиентов и финансов. Он
реализуется в формате Озера данных (на базе Delta Lake или Apache
Iceberg) и обеспечивает сквозной контроль качества, управление
метаданными и безопасный доступ через API и векторные индексы. Поверх
создаётся вычислительный слой на Kubernetes с поддержкой GPU-ресурсов
для обучения и инференса моделей, а также гибридное подключение к
облачным сервисам.

На этом уровне внедряются процессы MLOps и LLMOps: автоматизированный
цикл подготовки данных, обучения моделей, тестирования, развёртывания,
мониторинга и переобучения. Используются инструменты MLflow и Kubeflow
для регистрации и доставки моделей, Evidently AI - для контроля качества
и дрифта. Векторные индексы и семантические поисковые механизмы
становятся стандартом для всех RAG-сценариев.

Для разных типов ИИ формируются собственные вычислительные контуры:

-   для генеративных моделей - выделенные GPU-узлы с
    высокопроизводительным NVMe-хранилищем и системой безопасного
    контент-фильтра;

-   для ML и CV - кластеры с ускорителями L40S / A100, интегрированные с
    системами сбора телеметрии;

-   для предиктивных аналитических моделей - CPU-пулы с повышенной
    памятью, работающие с данными Lakehouse;

-   для агентных систем - среда контейнеров с сервис-мэшем и API-шлюзами
    для интеграции с АСУП, ERP и CRM.

На организационном уровне формируется Центр компетенций по ИИ и данным,
отвечающий за архитектуру платформы, стандарты данных, управление
моделями и безопасность. Для эксплуатации инфраструктуры создаются роли
инженеров данных, ML/LLM-инженеров, MLOps-специалистов и администраторов
платформы.

### Целевая корпоративная архитектура ИТ для ИИ

Долгосрочная цель - создание единой корпоративной ИИ-платформы,
интегрированной с ИТ-ландшафтом ҚТЖ. Она объединяет все типы
искусственного интеллекта в общую когнитивную экосистему, где данные,
модели и процессы связаны через события, API и мультиагентные механизмы.

Архитектура должна поддерживать полную совместимость с операционными и
техническими системами компании, обеспечивая онлайн-обмен данными между
перевозками, ТОиР, безопасностью и клиентскими сервисами.

-   На уровне данных создаётся корпоративное озеро данных с едиными
    политиками доступа и контролем, векторными индексами и механизмами
    событийной синхронизации

-   На уровне вычислений формируется гибридный кластер GPU и CPU,
    объединённый сервис-мэшем и управляемый через GitOps-модель.

-   На уровне моделей - централизованный Model Registry с аудитом и
    аттестацией алгоритмов

-   Для мультиагентных сценариев (например, совместного планирования
    перевозок и ремонтов) используется событийная шина Kafka и
    координационные модули reinforcement learning

-   Для обеспечения прозрачности и безопасности в архитектуру встроены
    средства киберзащиты (IAM, DLP, аудит моделей, трассировка решений)
    и система мониторинга эксплуатационных метрик (SLO, drift,
    точность).

<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 18%" />
<col style="width: 24%" />
<col style="width: 21%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Слой архитектуры</strong></th>
<th><strong>Компонент / функция</strong></th>
<th><strong>Пример тех стека (пилоты)</strong></th>
<th><strong>Пример тех стека (масштабирвание)</strong></th>
<th><strong>Типы ИИ</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td rowspan="3">Инфраструктура и вычисления</td>
<td>GPU/CPU-ресурсы</td>
<td>Облачные GPU (Azure/AWS/«КазДата»),</td>
<td>Гибридный кластер Kubernetes с GPU-нодами, edge-узлы для
видеоаналитики</td>
<td>Все типы ИИ; ML/CV, LLM, RAG</td>
</tr>
<tr class="even">
<td>Контейнеризация и оркестрация</td>
<td>Docker, Minikube</td>
<td>Kubernetes + Istio/Linkerd (service mesh) + ArgoCD (GitOps)</td>
<td>Все</td>
</tr>
<tr class="odd">
<td>Хранение данных</td>
<td>Локальное S3-хранилище (MinIO)</td>
<td>Объектное хранилище S3-класса + Lakehouse (Delta Lake /
Iceberg)</td>
<td>Все; особенно ML/CV и предиктивные модели</td>
</tr>
<tr class="even">
<td rowspan="3">Данные и интеграция</td>
<td>Интеграция потоков</td>
<td>Простые ETL-скрипты, API выгрузки</td>
<td>Kafka / Redpanda + Debezium (CDC), Airflow / Prefect, dbt</td>
<td>ML, CV, предиктивные модели</td>
</tr>
<tr class="odd">
<td>Каталог данных и метаданные</td>
<td>OpenMetadata (on-prem)</td>
<td>DataHub / OpenMetadata + Great Expectations / Deequ</td>
<td>Все типы ИИ</td>
</tr>
<tr class="even">
<td>Качество и линейка данных</td>
<td>Ручная валидация, Great Expectations</td>
<td>Great Expectations + OpenLineage / Marquez</td>
<td>ML/CV, аналитика</td>
</tr>
<tr class="odd">
<td rowspan="3">Слой данных</td>
<td>Data Lake / Lakehouse</td>
<td>MinIO + Parquet</td>
<td>Iceberg / Delta Lake + Trino / Spark</td>
<td>ML/CV, предиктивные модели</td>
</tr>
<tr class="even">
<td>Векторные базы</td>
<td>pgvector (Postgres)</td>
<td>Qdrant / Milvus / Weaviate (on-prem)</td>
<td>LLM, RAG, ассистенты, поиск НТД</td>
</tr>
<tr class="odd">
<td>Поисковые движки</td>
<td>Elastic / OpenSearch</td>
<td>OpenSearch + Reranker (bge-reranker / Cohere)</td>
<td>LLM, RAG</td>
</tr>
<tr class="even">
<td rowspan="4">Платформа ИИ / MLOps / LLMOps</td>
<td>Управление экспериментами</td>
<td>MLflow (локально)</td>
<td>MLflow + Kubeflow / ZenML / Metaflow</td>
<td>ML, CV</td>
</tr>
<tr class="odd">
<td>Пайплайны / CI-CD моделей</td>
<td>Git + Airflow</td>
<td>Argo Workflows + KServe / Seldon</td>
<td>Все типы ИИ</td>
</tr>
<tr class="even">
<td>Мониторинг моделей</td>
<td>Evidently AI</td>
<td>Evidently / WhyLabs / Prometheus-метрики</td>
<td>ML, CV</td>
</tr>
<tr class="odd">
<td>Репозиторий моделей</td>
<td>MLflow Registry</td>
<td>MLflow / Hugging Face Hub (приватный)</td>
<td>Все</td>
</tr>
<tr class="even">
<td rowspan="4">Стек для LLM и генеративного ИИ</td>
<td>Генеративные модели</td>
<td>Azure OpenAI / Llama 3 API</td>
<td>vLLM / TGI (Text Generation Inference), TensorRT-LLM</td>
<td>LLM, RAG, ассистенты</td>
</tr>
<tr class="odd">
<td>Фреймворки</td>
<td>LangChain / LlamaIndex</td>
<td>LangChain + LangGraph / Semantic Kernel</td>
<td>LLM, агенты</td>
</tr>
<tr class="even">
<td>Векторизация и эмбеддинги</td>
<td>text-embedding-3-large / bge-large</td>
<td>E5-Large / KazLLM embeddings (on-prem)</td>
<td>LLM, RAG</td>
</tr>
<tr class="odd">
<td>Guardrails и фильтрация</td>
<td>OpenAI Moderation API</td>
<td>NeMo Guardrails / Guardrails.ai (локально)</td>
<td>LLM, чат-боты</td>
</tr>
<tr class="even">
<td rowspan="3">Стек для ML / CV / аналитики</td>
<td>Фреймворки обучения</td>
<td>scikit-learn, PyTorch</td>
<td>PyTorch Lightning, TensorFlow, ONNX Runtime</td>
<td>ML, CV</td>
</tr>
<tr class="odd">
<td>Компьютерное зрение</td>
<td>OpenCV, YOLOv8</td>
<td>Detectron2, MMDetection, Triton Inference Server</td>
<td>CV, предиктивное ТОиР</td>
</tr>
<tr class="even">
<td>Разметка данных</td>
<td>Label Studio (open source)</td>
<td>CVAT / Label Studio Enterprise</td>
<td>CV</td>
</tr>
<tr class="odd">
<td rowspan="2">Агентные и мультиагентные решения</td>
<td>Агентные фреймворки</td>
<td>LangChain Agents</td>
<td>Semantic Kernel / LangGraph + MCP-интеграция</td>
<td>Автоматизация процессов, ИИ-агенты</td>
</tr>
<tr class="even">
<td>Интеграция с ИС</td>
<td>REST API</td>
<td>API-шлюз (Kong, Apigee), gRPC / OPC UA, событийная шина Kafka</td>
<td>АСУП, ERP, CRM, SCADA</td>
</tr>
<tr class="odd">
<td rowspan="3">Безопасность, управление и аудит</td>
<td>IAM / доступы</td>
<td>Keycloak / Azure AD</td>
<td>OPA / Kyverno, Vault, SSO (AD / Keycloak)</td>
<td>Все</td>
</tr>
<tr class="even">
<td>Аудит и мониторинг</td>
<td>ELK / OpenSearch</td>
<td>SIEM (Wazuh, Splunk local), трассировка промптов (Langfuse)</td>
<td>Все</td>
</tr>
<tr class="odd">
<td>Кибербезопасность данных</td>
<td>DLP-сканеры / ручные проверки</td>
<td>DLP, токенизация, сетевые зоны, приватные API-эндпоинты</td>
<td>Все</td>
</tr>
<tr class="even">
<td rowspan="3">Разработка, интеграция, визуализация</td>
<td>Языки и SDK</td>
<td>Python, SQL</td>
<td>Python, Go, C#, API SDK</td>
<td>Все</td>
</tr>
<tr class="odd">
<td>CI/CD</td>
<td>GitLab CI, GitHub Actions</td>
<td>ArgoCD / Jenkins / GitOps</td>
<td>Все</td>
</tr>
<tr class="even">
<td>BI и фронт-энд</td>
<td>Metabase / Power BI</td>
<td>Power BI (on-prem), Superset, Next.js UI для ассистентов</td>
<td>LLM, аналитика</td>
</tr>
</tbody>
</table>

ИТ-среда поддерживающая внедрение искусственного интеллекта, должна
соответствовать ряду стратегических требований.

1.  Открытость и модульность архитектуры - использование промышленных
    стандартов (S3, Kubernetes, MLflow, OpenMetadata) для независимости
    от поставщиков и совместимости с локальными решениями.

2.  Гибридность и сегментация - критичные процессы (ТОиР, безопасность,
    диспетчеризация) должны выполняться внутри периметра, а
    вспомогательные функции (обучение моделей, аналитика текстов) могут
    использовать облачные мощности.

3.  Управляемость и воспроизводимость - все модели и пайплайны должны
    быть версионируемы, отслеживаемы и переобучаемы; результаты моделей
    подлежат аудиту.

4.  Безопасность и суверенность данных - хранение и обработка
    корпоративных и персональных данных исключительно на инфраструктуре
    ҚТЖ или сертифицированных облаках Казахстана.

5.  Масштабируемость и кадровая поддержка - ИТ-платформа должна
    проектироваться под рост числа моделей и пользователей, а
    эксплуатация - обеспечиваться Центром компетенций и внутренними
    ИИ-инженерами.

Таким образом, технологическая платформа ИИ - это не просто набор
систем, а сквозная архитектура, обеспечивающая работу всех типов
искусственного интеллекта в едином контуре данных, инфраструктуры и
управления. На старте - гибридная среда для пилотов; на этапе
масштабирования - управляемая платформа данных и моделей; в целевом
состоянии - корпоративная экосистема, где ИИ интегрирован в операционную
модель компании и поддерживает ключевые процессы железнодорожного
транспорта в режиме интеллектуального управления.
